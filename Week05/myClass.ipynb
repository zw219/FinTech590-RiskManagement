{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b48e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import *\n",
    "from numpy import diag, inf\n",
    "from numpy import copy, dot\n",
    "from numpy.linalg import norm\n",
    "from numpy import linalg as LA\n",
    "from datetime import datetime\n",
    "from random import *\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c441c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1 a\n",
    "def get_exp_weighted_cov_matrix(path):\n",
    "    seed(1)\n",
    "    returns = pd.read_csv(path)\n",
    "    returns.drop(returns.columns[0], axis=1, inplace= True)\n",
    "    means = returns.mean()\n",
    "    size = len(returns.columns)\n",
    "    returns.cov().to_csv('regular_cov.csv', index=False)\n",
    "    returns.corr().to_csv('regular_corr.csv', index=False)\n",
    "    def cov(weights, i, j):\n",
    "        mean_i = means[i]\n",
    "        mean_j = means[j]\n",
    "        col_i = returns.iloc[:,i]\n",
    "        col_j = returns.iloc[:,j]\n",
    "        cov_list = weights * (col_i - mean_i)* (col_j - mean_j)\n",
    "        return sum(cov_list)\n",
    "    \n",
    "    def eigengraph(λ):\n",
    "        weights = [(1-λ)*λ**(i-1) for i in range(1, len(returns.index)+1) ]\n",
    "        weights = [weight/sum(weights) for weight in weights]\n",
    "        cov_matrix = [ [ cov(weights, i, j) for i in range(size) ] for j in range(size) ]\n",
    "        e_value, e_vector = LA.eig(np.array(cov_matrix))\n",
    "        e_value.sort()\n",
    "        e_value = e_value[::-1]\n",
    "        cumulative_var = np.array([sum(e_value[:i])/sum(e_value) for i in range(1, len(e_value) + 1)],dtype = \"complex_\")\n",
    "        plt.plot([i for i in range(len(e_value))],cumulative_var)\n",
    "        plt.title('λ = ' + str(λ) + ' cumulative eigenvalue graph')\n",
    "        plt.ylabel('cumulative variance')\n",
    "        plt.xlabel('K value')\n",
    "        plt.show()\n",
    "        return cov_matrix\n",
    "    c1 = pd.DataFrame(eigengraph(0.97), columns = returns.columns, index = returns.columns)\n",
    "    corr_matrix = [[0 for i in range(len(c1))] for j in range(len(c1))]\n",
    "    for i in range(len(c1)):\n",
    "        for j in range(i, len(c1)):\n",
    "            if i == j:\n",
    "                corr_matrix[i][j] = 1.0\n",
    "                continue\n",
    "            cov = c1.iloc[i][j]\n",
    "            stdi = math.sqrt(c1.iloc[i][i])\n",
    "            stdj = math.sqrt(c1.iloc[j][j])\n",
    "            corr_matrix[i][j] = cov/stdi/stdj\n",
    "            corr_matrix[j][i] = corr_matrix[i][j]\n",
    "    corr_matrix = pd.DataFrame(corr_matrix, columns = returns.columns, index = returns.columns)\n",
    "    corr_matrix.to_csv(\"97_corr.csv\", index=False)\n",
    "    c1.to_csv(\"97_cov.csv\",index=False)\n",
    "    return c1\n",
    "\n",
    "\n",
    "def get_reg_cov_matrix(path):\n",
    "    returns = pd.read_csv(path)\n",
    "    return returns.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e68850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef87cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2\n",
    "# https://stackify.dev/670594-how-can-i-calculate-the-nearest-positive-semi-definite-matrix\n",
    "def nearPSD(A, n, epsilon=0.0):\n",
    "    eigval, eigvec = np.linalg.eig(A)\n",
    "    val = np.matrix(np.maximum(eigval,epsilon))\n",
    "    vec = np.matrix(eigvec)\n",
    "    T = 1/(np.multiply(vec,vec) * val.T)\n",
    "    T = np.matrix(np.sqrt(np.diag(np.array(T).reshape((n)) )))\n",
    "    B = T * vec * np.diag(np.array(np.sqrt(val)).reshape((n)))\n",
    "    out = B*B.T\n",
    "    return np.asarray(out)\n",
    "\n",
    "# https://github.com/mikecroucher/nearest_correlation/blob/master/nearest_correlation.py\n",
    "def nearcorr(A, tol=[], flag=0, max_iterations=100, n_pos_eig=0,\n",
    "             weights=None, verbose=False,\n",
    "             except_on_too_many_iterations=True):\n",
    "\n",
    "    if (isinstance(A, ValueError)):\n",
    "        ds = copy(A.ds)\n",
    "        A = copy(A.matrix)\n",
    "    else:\n",
    "        ds = np.zeros(np.shape(A))\n",
    "\n",
    "    eps = np.spacing(1)\n",
    "    if not np.all((np.transpose(A) == A)):\n",
    "        raise ValueError('Input Matrix is not symmetric')\n",
    "    if not tol:\n",
    "        tol = eps * np.shape(A)[0] * np.array([1, 1])\n",
    "    if weights is None:\n",
    "        weights = np.ones(np.shape(A)[0])\n",
    "    X = copy(A)\n",
    "    Y = copy(A)\n",
    "    rel_diffY = inf\n",
    "    rel_diffX = inf\n",
    "    rel_diffXY = inf\n",
    "\n",
    "    Whalf = np.sqrt(np.outer(weights, weights))\n",
    "\n",
    "    iteration = 0\n",
    "    while max(rel_diffX, rel_diffY, rel_diffXY) > tol[0]:\n",
    "        iteration += 1\n",
    "        if iteration > max_iterations:\n",
    "            if except_on_too_many_iterations:\n",
    "                if max_iterations == 1:\n",
    "                    message = \"No solution found in \"\\\n",
    "                              + str(max_iterations) + \" iteration\"\n",
    "                else:\n",
    "                    message = \"No solution found in \"\\\n",
    "                              + str(max_iterations) + \" iterations\"\n",
    "                raise ValueError(message, X, iteration, ds)\n",
    "            else:\n",
    "\n",
    "                return X\n",
    "\n",
    "        Xold = copy(X)\n",
    "        R = X - ds\n",
    "        R_wtd = Whalf*R\n",
    "        if flag == 0:\n",
    "            X = proj_spd(R_wtd)\n",
    "        elif flag == 1:\n",
    "            raise ValueError(\"Setting 'flag' to 1 is currently\\\n",
    "                                 not implemented.\")\n",
    "        X = X / Whalf\n",
    "        ds = X - R\n",
    "        Yold = copy(Y)\n",
    "        Y = copy(X)\n",
    "        np.fill_diagonal(Y, 1)\n",
    "        normY = norm(Y, 'fro')\n",
    "        rel_diffX = norm(X - Xold, 'fro') / norm(X, 'fro')\n",
    "        rel_diffY = norm(Y - Yold, 'fro') / normY\n",
    "        rel_diffXY = norm(Y - X, 'fro') / normY\n",
    "        X = copy(Y)\n",
    "    return X\n",
    "\n",
    "def proj_spd(A):\n",
    "    d, v = np.linalg.eigh(A)\n",
    "    A = (v * np.maximum(d, 0)).dot(v.T)\n",
    "    A = (A + A.T) / 2\n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef42061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3\n",
    "def simulation(path):\n",
    "    get_exp_weighted_cov_matrix(path)\n",
    "    def chol_psd(root, sigma, n):\n",
    "        root = [ [ 0 for i in range(n) ] for j in range(n) ]\n",
    "        sigma = np.array(sigma)\n",
    "        for j in range(n):\n",
    "            s = 0.0\n",
    "            if j > 0:\n",
    "                s = sum([root[j][i]**2 for i in range(j)])\n",
    "            temp = sigma[j][j] - s\n",
    "            if temp <= 0:\n",
    "                temp = 0.0\n",
    "            root[j][j] = np.sqrt(temp)\n",
    "            if 0.0 == root[j][j]:\n",
    "                for i in range(j +1, n ):\n",
    "                    root[j][i] = 0.0\n",
    "            else:\n",
    "                ir = 1.0 / root[j][j]\n",
    "                for i in range(j+1, n): \n",
    "                    # may be wrong \n",
    "                    s = sum([root[i][k] * root[j][i] for k in range(j)])\n",
    "                    root[i][j] = (sigma[i][j] - s) * ir\n",
    "        return root\n",
    "\n",
    "    def simulateNormal(cap_n, cov, mean=[], seed=1234):\n",
    "        n, m = len(cov), len(cov[0])\n",
    "        if n != m:\n",
    "            raise Exception()\n",
    "            return\n",
    "        np.random.seed = seed\n",
    "        temp_mean = [0.0 for i in range(n)]\n",
    "        # maybe wrong\n",
    "        m = len(mean)\n",
    "        if m != 0:\n",
    "            if n != m:\n",
    "                raise Exception()\n",
    "            else:\n",
    "                temp_mean = mean\n",
    "\n",
    "        root = np.empty([n, cap_n])\n",
    "        root = chol_psd(root, cov, n)\n",
    "\n",
    "        mu, sigma = 0.0, 1.0 # mean and standard deviation\n",
    "        out = np.random.normal(mu, sigma, (n, cap_n))\n",
    "\n",
    "        out = np.matmul(root, out).transpose()\n",
    "\n",
    "        for j in range(n):\n",
    "            for i in range(cap_n):\n",
    "                out[i][j] = out[i][j] + temp_mean[j] \n",
    "        return out\n",
    "    def simulate_pca(a, nsim, pctExp=1, mean=[], seed=1234):\n",
    "        n = len(a)\n",
    "        temp_mean = [0.0 for i in range(n)]\n",
    "        if len(mean) > 0:\n",
    "            temp_mean = mean\n",
    "        vals, vecs = np.linalg.eig(np.array(a))\n",
    "    #     少一步 vals = real.(vals)\n",
    "        posv = [idx for idx in range(len(vals)) if vals[idx] > 0]\n",
    "        vals.sort()\n",
    "        vals = vals[::-1] \n",
    "        tv = sum(vals)\n",
    "        if pctExp < 1:\n",
    "            nval = 0\n",
    "            pct = 0.0\n",
    "            for i in range(len(posv)):\n",
    "                pct += vals[i]/tv\n",
    "                nval += 1\n",
    "                if pct >= pctExp:\n",
    "                    break\n",
    "            if nval < len(posv):\n",
    "                posv[:] = posv[0: nval]\n",
    "        tempvecs = []\n",
    "        for vec in vecs:\n",
    "            tempvec = []\n",
    "            for idx in posv:\n",
    "                tempvec.append(vec[idx])\n",
    "            tempvecs.append(tempvec)\n",
    "        vals = vals[:len(posv)]\n",
    "        vecs = tempvecs\n",
    "    #     B = vecs * np.diag(np.array(np.sqrt(vals)))\n",
    "        B = np.matmul(vecs, np.diag(np.array(np.sqrt(vals))))\n",
    "        np.random.seed = seed\n",
    "        m = len(vals)\n",
    "    #     randn(m, nsim)没懂\n",
    "        r = np.random.rand(m, nsim)\n",
    "        out = np.matmul(B, r).transpose()\n",
    "        for j in range(m):\n",
    "            for i in range(n):\n",
    "                out[i][j] = out[i][j] + temp_mean[i]\n",
    "        return out\n",
    "\n",
    "    covar = pd.read_csv(\"97_cov.csv\")\n",
    "    covar = np.array(covar)\n",
    "    # sim = simulateNormal(101, covar)\n",
    "    # sim = simulate_pca(covar,101,pctExp=.5)\n",
    "    pearson_cov = pd.read_csv(\"regular_cov.csv\")\n",
    "    pearson_std = pearson_cov.transform(lambda x:x**0.5)\n",
    "    pearson_cor = pd.read_csv(\"regular_corr.csv\")\n",
    "    ewma_cov = pd.read_csv(\"97_cov.csv\")\n",
    "    ewma_std = ewma_cov.transform(lambda x:x**0.5)\n",
    "    ewma_cor = pd.read_csv(\"97_corr.csv\")\n",
    "    matrixType = [\"EWMA\", \"EWMA_COR_PEARSON_STD\", \"PEARSON\", \"PEARSON_COR_EWMA_STD\"]\n",
    "    simType = [\"Full\", \"PCA=1\", \"PCA=0.75\", \"PCA=0.5\"]\n",
    "    matrixLookup = {}\n",
    "    matrixLookup[\"EWMA\"] = ewma_cov\n",
    "    matrixLookup[\"EWMA_COR_PEARSON_STD\"] = np.diag(np.array(pearson_std)) * ewma_cor * np.diag(np.array(pearson_std))\n",
    "    matrixLookup[\"PEARSON\"] = pearson_cov\n",
    "    matrixLookup[\"PEARSON_COR_EWMA_STD\"] = np.diag(np.array(ewma_std)) * pearson_cor * np.diag(np.array(ewma_std))\n",
    "\n",
    "    matrix = [\"\"] *16\n",
    "    simulation = [\"\"] *16\n",
    "    runtimes = [\"\"] *16\n",
    "    norms = [\"\"] *16\n",
    "\n",
    "    i = 0\n",
    "    for sim in simType:\n",
    "        for mat in matrixType:\n",
    "            matrix[i] = mat\n",
    "            simulation[i] = sim\n",
    "            c = np.array(matrixLookup[mat])\n",
    "            elapse = 0.0\n",
    "            s = []\n",
    "            st = datetime.now()\n",
    "            if sim == \"Full\":\n",
    "                for loops in range(20):\n",
    "                    s = simulateNormal(25000, c).transpose()\n",
    "            elif sim ==\"PCA=1\":\n",
    "                for loops in range(20):\n",
    "                    s = simulate_pca(c,25000,pctExp=1).transpose()\n",
    "            elif sim==\"PCA=0.75\":\n",
    "                for loops in range(20):\n",
    "                    s = simulate_pca(c,25000,pctExp=.75).transpose()\n",
    "            else:\n",
    "                for loops in range(20):\n",
    "                    s = simulate_pca(c,25000,pctExp=.5).transpose()\n",
    "            elapse = (datetime.now() - st)/20\n",
    "            covar = np.cov(s)\n",
    "\n",
    "            runtimes[i] = elapse\n",
    "            norms[i] = sum( np.dot(covar-c, covar-c))\n",
    "            i = i+1    \n",
    "    outTable = pd.DataFrame(data={'matrix': matrix, 'simulation': simulation, 'runtimes': runtimes, 'norms': norms})\n",
    "    return outTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03208241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_var(path, ticker):\n",
    "    returns = pd.read_csv(path)\n",
    "    ticker = returns[ticker]\n",
    "    tick_mean = ticker.mean()\n",
    "    tick_demean = ticker - tick_mean\n",
    "    # normal dist from here\n",
    "    std = np.std(tick_demean)\n",
    "    var_n = 1.65 * std\n",
    "    return var_n\n",
    "    return\n",
    "\n",
    "def mleTVaR(path, ticker, alpha):\n",
    "    returns = pd.read_csv(path)\n",
    "    ret = returns[ticker]\n",
    "    mu_norm, std_norm = norm.fit(ret)\n",
    "    \n",
    "    def negLogLikeForT(initialParams):\n",
    "        df, sigma = initialParams\n",
    "        return -t(df=df, scale=sigma).logpdf(ret).sum()\n",
    "    initialParams = np.array([1, 1])\n",
    "    df, sigma = minimize(negLogLikeForT, initialParams, method=\"BFGS\").x\n",
    "    return -t.ppf(alpha, df, loc=ret.mean(), scale=sigma)\n",
    "\n",
    "# Historical var\n",
    "def VaR_hist(path, Confidence_Interval = 0.95 , Period_Interval = None ,\n",
    "        Series = False ,removeNa = True):\n",
    "    Returns = pd.read_csv(path)\n",
    "    Returns.drop(Returns.columns[0], axis=1, inplace= True)\n",
    "    if removeNa==True: Returns = Returns[pd.notnull(Returns)]\n",
    "\n",
    "    if (Series == True and Period_Interval == None):\n",
    "        Period_Interval = 100\n",
    "    elif Period_Interval == None: \n",
    "        Period_Interval = len(Returns)\n",
    "        \n",
    "    if Series == False:\n",
    "        Data = Returns[-Period_Interval:]\n",
    "        Value_at_Risk = -np.percentile(Data,1-Confidence_Interval)\n",
    "    if Series == True:\n",
    "        Value_at_Risk = pd.Series(index=Returns.index, name = 'HSVaR')\n",
    "        for i in range(0,len(Returns)-Period_Interval):\n",
    "            if i == 0: Data = Returns[-(Period_Interval):]\n",
    "            else: Data = Returns[-(Period_Interval+i):-i]\n",
    "            Value_at_Risk[-i-1] = -np.percentile(Data,1-Confidence_Interval)\n",
    "    return(Value_at_Risk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6379591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES_n(path, ticker, alpha):\n",
    "    returns = pd.read_csv(path)\n",
    "    ret = returns[ticker]\n",
    "    mu_norm, std_norm = norm.fit(ret)\n",
    "    return alpha**-1 * norm.pdf(norm.ppf(alpha))*std_norm - mu_norm\n",
    "\n",
    "def ES_t(path, ticker, alpha):\n",
    "    returns = pd.read_csv(path)\n",
    "    p1 = returns[ticker]\n",
    "    mu_norm, std_norm = norm.fit(p1)\n",
    "    xanu = t.ppf(alpha, (len(p1.index) - 1))\n",
    "    return -1/alpha * (1-(len(p1.index) - 1))**(-1) * ((len(p1.index) - 1)-2+xanu**2) * t.pdf(xanu, (len(p1.index) - 1))*std_norm - mu_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf08a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029925416110891605"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES_t(\"DailyReturn.csv\", \"AAPL\", 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8783f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
